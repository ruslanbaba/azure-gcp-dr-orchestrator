# Security-Hardened Kubernetes Manifests with Canary Deployment Support
# Implements Pod Security Standards, Network Policies, and Workload Identity

---
apiVersion: v1
kind: Namespace
metadata:
  name: dr-system
  labels:
    # Pod Security Standards
    pod-security.kubernetes.io/enforce: restricted
    pod-security.kubernetes.io/audit: restricted  
    pod-security.kubernetes.io/warn: restricted
    
    # Istio injection
    istio-injection: enabled
    
    # Common labels
    app.kubernetes.io/name: dr-orchestrator
    app.kubernetes.io/part-of: disaster-recovery
    app.kubernetes.io/managed-by: terraform

---
# Service Account with Workload Identity
apiVersion: v1
kind: ServiceAccount
metadata:
  name: dr-app-service-account
  namespace: dr-system
  annotations:
    iam.gke.io/gcp-service-account: dr-orchestrator-sa@PROJECT_ID.iam.gserviceaccount.com
  labels:
    app.kubernetes.io/name: dr-orchestrator
    app.kubernetes.io/component: service-account

---
# Network Policy for strict network segmentation
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: dr-network-policy
  namespace: dr-system
  labels:
    app.kubernetes.io/name: dr-orchestrator
    app.kubernetes.io/component: network-policy
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
  
  # Ingress rules
  ingress:
  # Allow Istio sidecar traffic
  - from:
    - namespaceSelector:
        matchLabels:
          name: istio-system
    ports:
    - protocol: TCP
      port: 15000  # Envoy admin
    - protocol: TCP  
      port: 15001  # Envoy proxy
    - protocol: TCP
      port: 15006  # Envoy inbound
    - protocol: TCP
      port: 15090  # Envoy health check
  
  # Allow ingress from istio-gateway
  - from:
    - namespaceSelector:
        matchLabels:
          name: istio-system
    - podSelector:
        matchLabels:
          app: istio-proxy
    ports:
    - protocol: TCP
      port: 8080

  # Allow metrics scraping
  - from:
    - namespaceSelector:
        matchLabels:
          name: monitoring
    ports:
    - protocol: TCP
      port: 15020  # Istio metrics
    - protocol: TCP
      port: 9090   # App metrics
  
  # Egress rules
  egress:
  # Allow DNS
  - to: []
    ports:
    - protocol: UDP
      port: 53
    - protocol: TCP
      port: 53
  
  # Allow HTTPS to external services
  - to: []
    ports:
    - protocol: TCP
      port: 443
  
  # Allow Cloud SQL Proxy
  - to: []
    ports:
    - protocol: TCP
      port: 5432  # PostgreSQL
  
  # Allow Istio control plane
  - to:
    - namespaceSelector:
        matchLabels:
          name: istio-system
    ports:
    - protocol: TCP
      port: 15010  # Pilot
    - protocol: TCP
      port: 15011  # Pilot
    - protocol: TCP
      port: 15014  # Pilot debug

---
# Security Context Constraints via Pod Security Policy (if enabled)
apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  name: dr-restricted-psp
  labels:
    app.kubernetes.io/name: dr-orchestrator
    app.kubernetes.io/component: security-policy
spec:
  privileged: false
  allowPrivilegeEscalation: false
  requiredDropCapabilities:
    - ALL
  volumes:
    - 'configMap'
    - 'emptyDir'
    - 'projected'
    - 'secret'
    - 'downwardAPI'
    - 'persistentVolumeClaim'
  runAsUser:
    rule: 'MustRunAsNonRoot'
  supplementalGroups:
    rule: 'MustRunAs'
    ranges:
      - min: 1
        max: 65535
  fsGroup:
    rule: 'MustRunAs'
    ranges:
      - min: 1
        max: 65535
  readOnlyRootFilesystem: true
  seLinux:
    rule: 'RunAsAny'

---
# RBAC for the service account
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: dr-app-role
  labels:
    app.kubernetes.io/name: dr-orchestrator
    app.kubernetes.io/component: rbac
rules:
# Minimal permissions for health checks and metrics
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list"]
- apiGroups: [""]
  resources: ["services", "endpoints"]  
  verbs: ["get", "list"]
- apiGroups: ["apps"]
  resources: ["deployments", "replicasets"]
  verbs: ["get", "list"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: dr-app-binding
  labels:
    app.kubernetes.io/name: dr-orchestrator
    app.kubernetes.io/component: rbac
subjects:
- kind: ServiceAccount
  name: dr-app-service-account
  namespace: dr-system
roleRef:
  kind: ClusterRole
  name: dr-app-role
  apiGroup: rbac.authorization.k8s.io

---
# ConfigMap for application configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: dr-app-config
  namespace: dr-system
  labels:
    app.kubernetes.io/name: dr-orchestrator
    app.kubernetes.io/component: config
data:
  # Application configuration
  log_level: "INFO"
  metrics_port: "9090"
  health_check_port: "8080"
  
  # Database configuration
  db_pool_size: "10"
  db_max_connections: "20"
  db_connection_timeout: "30"
  
  # Security configuration
  enable_tls: "true"
  require_auth: "true"
  
  # Canary configuration
  canary_traffic_percentage: "10"
  canary_success_threshold: "95"
  canary_timeout_seconds: "300"

---
# Secret placeholder - actual secrets should be managed by External Secrets Operator
apiVersion: v1
kind: Secret
metadata:
  name: dr-app-secrets
  namespace: dr-system
  labels:
    app.kubernetes.io/name: dr-orchestrator
    app.kubernetes.io/component: secrets
type: Opaque
stringData:
  # These will be populated by External Secrets Operator or Secret Manager CSI
  gcp-database-url: "placeholder://will-be-replaced-by-secret-manager"
  api-key: "placeholder://will-be-replaced-by-secret-manager"
  tls-cert: "placeholder://will-be-replaced-by-secret-manager"
  tls-key: "placeholder://will-be-replaced-by-secret-manager"

---
# Main Application Deployment (Production)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: dr-app-production
  namespace: dr-system
  labels:
    app.kubernetes.io/name: dr-orchestrator
    app.kubernetes.io/component: application
    app.kubernetes.io/version: production
    version: production
spec:
  replicas: 0  # Initially scaled to 0, will be scaled up during failover
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  selector:
    matchLabels:
      app: dr-app
      version: production
  template:
    metadata:
      labels:
        app: dr-app
        version: production
        app.kubernetes.io/name: dr-orchestrator
        app.kubernetes.io/component: application
      annotations:
        # Istio sidecar configuration
        sidecar.istio.io/inject: "true"
        sidecar.istio.io/proxyCPU: "100m"
        sidecar.istio.io/proxyMemory: "128Mi"
        
        # Security annotations
        container.seccomp.security.alpha.kubernetes.io/pod: runtime/default
        
        # Prometheus scraping
        prometheus.io/scrape: "true"
        prometheus.io/port: "9090"
        prometheus.io/path: "/metrics"
    spec:
      serviceAccountName: dr-app-service-account
      
      # Security context for the pod
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        runAsGroup: 3000
        fsGroup: 2000
        fsGroupChangePolicy: "OnRootMismatch"
        seccompProfile:
          type: RuntimeDefault
      
      # Topology spread constraints for high availability
      topologySpreadConstraints:
      - maxSkew: 1
        topologyKey: topology.kubernetes.io/zone
        whenUnsatisfiable: DoNotSchedule
        labelSelector:
          matchLabels:
            app: dr-app
            version: production
      
      # Node affinity for dedicated nodes
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: role
                operator: In
                values: ["app"]
        
        # Pod anti-affinity for spreading across nodes
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values: ["dr-app"]
              topologyKey: kubernetes.io/hostname
      
      # Init container for database migration/setup
      initContainers:
      - name: db-setup
        image: postgres:15-alpine
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          runAsNonRoot: true
          runAsUser: 1000
          capabilities:
            drop:
            - ALL
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: dr-app-secrets
              key: gcp-database-url
        command:
        - /bin/sh
        - -c
        - |
          echo "Checking database connectivity..."
          # Add database setup/migration logic here
          echo "Database setup complete"
        volumeMounts:
        - name: tmp
          mountPath: /tmp
        resources:
          requests:
            memory: "64Mi"
            cpu: "50m"
          limits:
            memory: "128Mi"
            cpu: "100m"
      
      containers:
      # Main application container
      - name: app
        image: gcr.io/PROJECT_ID/dr-app:latest  # Replace with actual image
        imagePullPolicy: Always
        
        # Security context for container
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          runAsNonRoot: true
          runAsUser: 1000
          capabilities:
            drop:
            - ALL
        
        ports:
        - name: http
          containerPort: 8080
          protocol: TCP
        - name: metrics
          containerPort: 9090
          protocol: TCP
        
        env:
        # Application configuration
        - name: PORT
          value: "8080"
        - name: METRICS_PORT
          value: "9090"
        - name: LOG_LEVEL
          valueFrom:
            configMapKeyRef:
              name: dr-app-config
              key: log_level
        - name: MODE
          value: "PRODUCTION"
        
        # Database configuration
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: dr-app-secrets
              key: gcp-database-url
        - name: DB_POOL_SIZE
          valueFrom:
            configMapKeyRef:
              name: dr-app-config
              key: db_pool_size
        
        # Security configuration
        - name: ENABLE_TLS
          valueFrom:
            configMapKeyRef:
              name: dr-app-config
              key: enable_tls
        
        # GCP metadata
        - name: K8S_NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        - name: K8S_POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: K8S_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        
        # Resource limits and requests
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
            ephemeral-storage: "1Gi"
          limits:
            memory: "512Mi"
            cpu: "500m"
            ephemeral-storage: "2Gi"
        
        # Health checks
        livenessProbe:
          httpGet:
            path: /health
            port: http
            scheme: HTTP
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 3
        
        readinessProbe:
          httpGet:
            path: /ready
            port: http
            scheme: HTTP
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 3
          successThreshold: 1
          failureThreshold: 2
        
        startupProbe:
          httpGet:
            path: /startup
            port: http
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 10
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 30
        
        # Volume mounts (read-only root filesystem)
        volumeMounts:
        - name: tmp
          mountPath: /tmp
        - name: cache
          mountPath: /app/cache
        - name: logs
          mountPath: /app/logs
        - name: config
          mountPath: /app/config
          readOnly: true
      
      # Volumes
      volumes:
      - name: tmp
        emptyDir:
          sizeLimit: 100Mi
      - name: cache
        emptyDir:
          sizeLimit: 500Mi
      - name: logs
        emptyDir:
          sizeLimit: 1Gi
      - name: config
        configMap:
          name: dr-app-config
          defaultMode: 0444
      
      # DNS configuration
      dnsPolicy: ClusterFirst
      dnsConfig:
        options:
        - name: ndots
          value: "2"
        - name: edns0
      
      # Restart policy
      restartPolicy: Always
      
      # Termination grace period
      terminationGracePeriodSeconds: 30

---
# Canary Deployment (for gradual rollout)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: dr-app-canary
  namespace: dr-system
  labels:
    app.kubernetes.io/name: dr-orchestrator
    app.kubernetes.io/component: application
    app.kubernetes.io/version: canary
    version: canary
spec:
  replicas: 0  # Initially scaled to 0, managed by Cloud Function
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  selector:
    matchLabels:
      app: dr-app
      version: canary
  template:
    metadata:
      labels:
        app: dr-app
        version: canary
        app.kubernetes.io/name: dr-orchestrator
        app.kubernetes.io/component: application
      annotations:
        sidecar.istio.io/inject: "true"
        prometheus.io/scrape: "true"
        prometheus.io/port: "9090"
        prometheus.io/path: "/metrics"
    spec:
      # Same configuration as production but with different labels
      serviceAccountName: dr-app-service-account
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        runAsGroup: 3000
        fsGroup: 2000
        seccompProfile:
          type: RuntimeDefault
      
      containers:
      - name: app
        image: gcr.io/PROJECT_ID/dr-app:canary  # Canary image version
        imagePullPolicy: Always
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          runAsNonRoot: true
          runAsUser: 1000
          capabilities:
            drop:
            - ALL
        ports:
        - name: http
          containerPort: 8080
        - name: metrics
          containerPort: 9090
        env:
        - name: MODE
          value: "CANARY"
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: dr-app-secrets
              key: gcp-database-url
        - name: LOG_LEVEL
          value: "DEBUG"  # More verbose logging for canary
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: http
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: http
          initialDelaySeconds: 5
          periodSeconds: 5
        volumeMounts:
        - name: tmp
          mountPath: /tmp
        - name: cache
          mountPath: /app/cache
      volumes:
      - name: tmp
        emptyDir: {}
      - name: cache
        emptyDir: {}

---
# Service for the application
apiVersion: v1
kind: Service
metadata:
  name: dr-app-service
  namespace: dr-system
  labels:
    app.kubernetes.io/name: dr-orchestrator
    app.kubernetes.io/component: service
spec:
  type: ClusterIP
  selector:
    app: dr-app
    # No version selector - serves both production and canary
  ports:
  - name: http
    port: 80
    targetPort: http
    protocol: TCP
  - name: metrics
    port: 9090
    targetPort: metrics
    protocol: TCP

---
# Separate service for canary (for traffic splitting)
apiVersion: v1
kind: Service
metadata:
  name: dr-app-canary-service
  namespace: dr-system
  labels:
    app.kubernetes.io/name: dr-orchestrator
    app.kubernetes.io/component: service
    version: canary
spec:
  type: ClusterIP
  selector:
    app: dr-app
    version: canary
  ports:
  - name: http
    port: 80
    targetPort: http
    protocol: TCP

---
# Service for production (for traffic splitting)
apiVersion: v1
kind: Service
metadata:
  name: dr-app-production-service
  namespace: dr-system
  labels:
    app.kubernetes.io/name: dr-orchestrator
    app.kubernetes.io/component: service
    version: production
spec:
  type: ClusterIP
  selector:
    app: dr-app
    version: production
  ports:
  - name: http
    port: 80
    targetPort: http
    protocol: TCP

---
# Horizontal Pod Autoscaler
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: dr-app-hpa
  namespace: dr-system
  labels:
    app.kubernetes.io/name: dr-orchestrator
    app.kubernetes.io/component: autoscaler
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: dr-app-production
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percentage
        value: 50
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percentage
        value: 100
        periodSeconds: 60

---
# Pod Disruption Budget
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: dr-app-pdb
  namespace: dr-system
  labels:
    app.kubernetes.io/name: dr-orchestrator
    app.kubernetes.io/component: disruption-budget
spec:
  selector:
    matchLabels:
      app: dr-app
  maxUnavailable: 1

---
# Istio VirtualService for traffic management
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: dr-app-virtualservice
  namespace: dr-system
  labels:
    app.kubernetes.io/name: dr-orchestrator
    app.kubernetes.io/component: traffic-management
spec:
  hosts:
  - dr-app-service
  - app.example.com  # External hostname
  gateways:
  - dr-app-gateway
  - mesh  # For internal traffic
  http:
  # Canary traffic routing (10% to canary, 90% to production)
  - match:
    - headers:
        canary:
          exact: "true"
    route:
    - destination:
        host: dr-app-canary-service
        port:
          number: 80
    fault:
      delay:
        percentage:
          value: 0.1
        fixedDelay: 5s
  - route:
    - destination:
        host: dr-app-production-service
        port:
          number: 80
      weight: 90
    - destination:
        host: dr-app-canary-service
        port:
          number: 80
      weight: 10
    timeout: 30s
    retries:
      attempts: 3
      perTryTimeout: 10s
      retryOn: 5xx,reset,connect-failure,refused-stream

---
# Istio Gateway for external traffic
apiVersion: networking.istio.io/v1beta1
kind: Gateway
metadata:
  name: dr-app-gateway
  namespace: dr-system
  labels:
    app.kubernetes.io/name: dr-orchestrator
    app.kubernetes.io/component: gateway
spec:
  selector:
    istio: ingressgateway
  servers:
  - port:
      number: 443
      name: https
      protocol: HTTPS
    tls:
      mode: SIMPLE
      credentialName: dr-app-tls-secret
    hosts:
    - app.example.com
  - port:
      number: 80
      name: http
      protocol: HTTP
    hosts:
    - app.example.com
    # Redirect HTTP to HTTPS
    tls:
      httpsRedirect: true

---
# Istio DestinationRule for circuit breaking and load balancing
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: dr-app-destination-rule
  namespace: dr-system
  labels:
    app.kubernetes.io/name: dr-orchestrator
    app.kubernetes.io/component: traffic-management
spec:
  host: dr-app-service
  trafficPolicy:
    connectionPool:
      tcp:
        maxConnections: 100
      http:
        http1MaxPendingRequests: 10
        http2MaxRequests: 100
        maxRequestsPerConnection: 2
        maxRetries: 3
        consecutiveGatewayErrors: 5
        interval: 30s
        baseEjectionTime: 30s
        maxEjectionPercent: 50
    loadBalancer:
      simple: LEAST_CONN
    outlierDetection:
      consecutiveGatewayErrors: 5
      interval: 30s
      baseEjectionTime: 30s
      maxEjectionPercent: 50
      minHealthPercent: 50
  portLevelSettings:
  - port:
      number: 80
    connectionPool:
      tcp:
        maxConnections: 50

---
# ServiceMonitor for Prometheus scraping
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: dr-app-metrics
  namespace: dr-system
  labels:
    app.kubernetes.io/name: dr-orchestrator
    app.kubernetes.io/component: monitoring
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: dr-orchestrator
      app.kubernetes.io/component: service
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics
    scheme: http
  namespaceSelector:
    matchNames:
    - dr-system
